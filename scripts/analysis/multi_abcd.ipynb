{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import network_diffusion as nd\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from abcd import configuration_model, correlations, helpers\n",
    "from src.loaders.net_loader import load_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversed parameter for the configuration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(net: nd.MultilayerNetwork, mode: str) -> dict[str, list[dict]]:\n",
    "    \n",
    "    print(\"\\tComputing statistics\")\n",
    "    degree_stats, partition_stats, edges_stats = [], [], []\n",
    "\n",
    "    for la_name, lb_name in helpers.prepare_layer_pairs(net.layers.keys()):\n",
    "        print(\"\\t\\t\", la_name, lb_name)\n",
    "        aligned_layers = correlations.align_layers(net, la_name, lb_name, mode)\n",
    "\n",
    "        degree_stat = correlations.degrees_correlation(aligned_layers[la_name], aligned_layers[lb_name])\n",
    "        degree_stats.append({(la_name, lb_name): degree_stat})\n",
    "\n",
    "        partition_stat = correlations.partitions_correlation(aligned_layers[la_name], aligned_layers[lb_name])\n",
    "        partition_stats.append({(la_name, lb_name): partition_stat})\n",
    "\n",
    "        edges_stat = correlations.edges_r(aligned_layers[la_name], aligned_layers[lb_name])\n",
    "        edges_stats.append({(la_name, lb_name): edges_stat})\n",
    "\n",
    "    return {\n",
    "        \"degree\": degree_stats,\n",
    "        \"partition\": partition_stats,\n",
    "        \"edges\": edges_stats,\n",
    "    }\n",
    "\n",
    "def convert_to_correlation_matrix(statistics: dict[str, list[dict]]) -> dict[str, pd.DataFrame]:\n",
    "    return {\n",
    "        \"degree\": helpers.create_correlation_matrix(statistics[\"degree\"]),\n",
    "        \"partition\": helpers.create_correlation_matrix(statistics[\"partition\"]),\n",
    "        \"edges\": helpers.create_correlation_matrix(statistics[\"edges\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "def find_confoguration_setup(net: nd.MultilayerNetwork) -> pd.DataFrame:\n",
    "    print(\"\\tFinding configuration setup\")\n",
    "    q = {l_name: configuration_model.get_q(l_graph, net.get_actors_num()) for l_name, l_graph in net.layers.items()}\n",
    "    degrees = {l_name: configuration_model.get_degrees_stats(l_graph) for l_name, l_graph in net.layers.items()}\n",
    "    partitions = {l_name: configuration_model.get_partitions_stats(l_graph) for l_name, l_graph in net.layers.items()}\n",
    "    merged_stats = {l_name: {**degrees[l_name], **partitions[l_name], **{\"q\": q[l_name]}} for l_name in net.layers}\n",
    "    return pd.DataFrame(merged_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "\n",
    "def save_statistics(statistics: dict[str, pd.DataFrame], net_name: str, out_dir: Path) -> None:\n",
    "    out_dir.mkdir(exist_ok=True, parents=True)\n",
    "    for stat_name, stat_df in statistics.items():\n",
    "        stat_df.to_csv(out_dir / f\"{net_name}_{stat_name}.csv\")\n",
    "\n",
    "\n",
    "def plot_statistics(statistics: dict[str, pd.DataFrame], net_name: str) -> Figure:\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 6), gridspec_kw={\"width_ratios\": [33, 33, 33, 1]})\n",
    "    fig.tight_layout(pad=2.5, rect=(0.05, 0.05, 0.95, 0.95))\n",
    "\n",
    "    helpers.plot_heatmap(statistics[\"degree\"], ax[0], ax[-1], \"degrees\")\n",
    "    helpers.plot_heatmap(statistics[\"partition\"], ax[1], ax[-1], \"partitions\")\n",
    "    helpers.plot_heatmap(statistics[\"edges\"], ax[2], ax[-1], \"edges R\")\n",
    "\n",
    "    fig.suptitle(net_name)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"destructive\"\n",
    "networks = [\n",
    "    \"arxiv_netscience_coauthorship\",\n",
    "    \"aucs\",\n",
    "    \"cannes\",\n",
    "    \"ckm_physicians\",\n",
    "    \"eu_transportation\",\n",
    "    \"l2_course_net_1\",\n",
    "    \"lazega\",\n",
    "    \"timik1q2009\",\n",
    "    \"toy_network\",\n",
    "]\n",
    "\n",
    "workdir = Path(\"correlations\")\n",
    "workdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "pdf = PdfPages(workdir.joinpath(f\"correlations.pdf\"))\n",
    "for net_name in sorted(networks):\n",
    "\n",
    "    print(net_name)\n",
    "    _net = load_network(net_name, as_tensor=False)\n",
    "    net = helpers.prepare_network(_net)  # with this we're sure there's no isolated nodes\n",
    "    if net.is_directed(): raise ValueError(\"Only undirected networks can be processed right now!\")\n",
    "\n",
    "    statistics_raw = compute_statistics(net, mode)\n",
    "    statistics_df = convert_to_correlation_matrix(statistics_raw)\n",
    "    n = configuration_model.get_nb_actors(net)\n",
    "    l = configuration_model.get_nb_layers(net)\n",
    "    configuration_df = find_confoguration_setup(net)\n",
    "\n",
    "    save_statistics(statistics_df, net_name, workdir / \"correlations\")\n",
    "    figure = plot_statistics(statistics_df, f\"network: {net_name}, n={n}, l={l}\")\n",
    "    figure.savefig(pdf, format=\"pdf\")\n",
    "    plt.close(figure)\n",
    "    configuration_df.to_csv(workdir / f\"{net_name}_configuration.csv\")\n",
    "\n",
    "pdf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degrees_table(net: nd.MultilayerNetwork) -> pd.DataFrame:\n",
    "    net_degrees = {}\n",
    "    for l_name, l_graph in net.layers.items():\n",
    "        net_degrees[l_name] = dict(l_graph.degree())\n",
    "    return pd.DataFrame(net_degrees).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_netscience_coauthorship\n"
     ]
    }
   ],
   "source": [
    "networks = [\n",
    "    \"arxiv_netscience_coauthorship\",\n",
    "    \"aucs\",\n",
    "    \"cannes\",\n",
    "    \"ckm_physicians\",\n",
    "    \"eu_transportation\",\n",
    "    \"l2_course_net_1\",\n",
    "    \"lazega\",\n",
    "    \"timik1q2009\",\n",
    "    \"toy_network\",\n",
    "]\n",
    "\n",
    "workdir = Path(\"correlations/degree_sequences\")\n",
    "workdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for net_name in sorted(networks):\n",
    "\n",
    "    print(net_name)\n",
    "    _net = load_network(net_name, as_tensor=False)\n",
    "    net = helpers.prepare_network(_net)  # with this we're sure there's no isolated nodes\n",
    "    if net.is_directed(): raise ValueError(\"Only undirected networks can be processed right now!\")\n",
    "\n",
    "    degrees_table = get_degrees_table(net)\n",
    "    degrees_table.to_csv(workdir / f\"{net_name}_degrees.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infmax-mds-ltm-mln",
   "language": "python",
   "name": "infmax-mds-ltm-mln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
